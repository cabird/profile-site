%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Christian Bird at 2009-04-06 12:54:49 -0700   


%s% Saved with string  encoding Unicode (UTF-8) 

@Article{storey2020productivity,
author = {Storey, Margaret-Anne and Zimmermann, Tom and Bird, Christian and Czerwonka, Jacek and Murphy, Brendan and Kalliamvakou, Eirini},
title = {{Towards a Theory of Software Developer Job Satisfaction and Perceived Productivity}},
year = {2020},
month = {January},
journal = {IEEE Transactions on Software Engineering},
}

@article{than2020hackathon,
author = {Pe-Than, Ei Pa Pa and Nolte, Alexander and Filippova, Anna and Bird, Christian and Scallen, Steve and Herbsleb, James},
year = {to appear},
title = {{Corporate Hackathons, How and Why? A Multiple Case Study of Motivation, Projects Proposal and Selection, Goal Setting, Coordination, and Outcomes}},
journal = {Human-Computer Interaction (Journal)}
}

@inproceedings{mehta2020rex,
  author    = {Sonu Mehta and
               Ranjita Bhagwan and
               Rahul Kumar and
               Chetan Bansal and
               Chandra Shekhar Maddila and
               B. Ashok and
               Sumit Asthana and
               Christian Bird and
               Aditya Kumar},
  title     = {Rex: Preventing Bugs and Misconfiguration in Large Services Using
               Correlated Change Analysis},
  booktitle = {17th {USENIX} Symposium on Networked Systems Design and Implementation,
               {NSDI} 2020, Santa Clara, CA, USA, February 25-27, 2020},
  pages     = {435--448},
  publisher = {{USENIX} Association},
  year      = {2020},
  url       = {https://www.usenix.org/conference/nsdi20/presentation/mehta},
  timestamp = {Wed, 22 Apr 2020 15:53:29 +0200},
  biburl    = {https://dblp.org/rec/conf/nsdi/MehtaB0BMAABK20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{henkel2020dockermsr,
	author={Jordan Henkel and Christian Bird and Shuvendu K. Lahiri and Thomas Reps},
	title={{A Dataset of Dockerfiles}},
	booktitle={Proceedings of the International Conference on Mining Software Repositories},
	year={2020}
}



@inproceedings{henkel2020docker,
	author={Jordan Henkel and Christian Bird and Shuvendu K. Lahiri and Thomas Reps},
	title={{Learning from, Understanding, and Supporting DevOps Artifacts for Docker}},
	booktitle={Proceedings of the International Conference on Software Engineering},
	year={2020}
}


@ARTICLE{kochhar2020moving, 
	author={Pavneet Singh Kochhar and Eirini Kalliamvakou and Nachiappan Nagappan and Thomas Zimmermann and Christian Bird},
	title = {{Moving from Closed to Open Source: Observations from Six Transitioned Projects to GitHub}},
	journal={{IEEE Transactions on Software Engineering}}, 
	year={2020},
	month={to appear} 
}

@inproceedings{asthana2019whodo,
  author    = {Sumit Asthana and
               Rahul Kumar and
               Ranjita Bhagwan and
               Christian Bird and
               Chetan Bansal and
               Chandra Shekhar Maddila and
               Sonu Mehta and
               B. Ashok},
  title     = {WhoDo: automating reviewer suggestions at scale},
  booktitle = {Proceedings of the {ACM} Joint Meeting on European Software Engineering
               Conference and Symposium on the Foundations of Software Engineering (Industry Track)},
  pages     = {937--945},
  year      = {2019},
  doi       = {10.1145/3338906.3340449},
  timestamp = {Fri, 09 Aug 2019 14:13:18 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/sigsoft/AsthanaKBBBMMA19},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{codeflow2018,
  author    = {Jacek Czerwonka and
               Michaela Greiler and
               Christian Bird and
               Lucas Panjer and
               Terry Coatta},
  title     = {CodeFlow: Improving the Code Review Process at Microsoft},
  journal   = {{ACM} Queue},
  volume    = {16},
  number    = {5},
  pages     = {20},
  year      = {2018},
  doi       = {10.1145/3291276.3292420},
  timestamp = {Tue, 22 Jan 2019 09:53:50 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/queue/CzerwonkaGBPC18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@ARTICLE{kovalenko2019revrec, 
	author={Vladimir Kovalenko and Nava Tintarev and Evgeny Pasynkov and Christian Bird and Alberto Bacchelli},
	title = {{Does Reviewer Recommendation Help Developers?}},
	journal={{IEEE Transactions on Software Engineering}}, 
	year={2019},
	month={to appear} 
}

@ARTICLE{meyer2019today, 
	author={Andre N. Meyer and Earl T. Barr and Christian Bird and Thomas Zimmermann},
	title = {{Today was a Good Day: The Daily Life of Software Developers}},
	journal={{IEEE Transactions on Software Engineering}}, 
	year={2019},
	month={to appear} 
}

@ARTICLE{johnson2019environment, 
	author={Brittany Johnson and Thomas Zimmermann and Christian Bird},
	title = {{The Effect of Work Environments on Productivity and Satisfaction of Software Engineers}},
	journal={{IEEE Transactions on Software Engineering}}, 
	year={2019},
	month={to appear} 
}



@article{nolte2018you,
  title={{You Hacked and Now What?:-Exploring Outcomes of a Corporate Hackathon}},
  author={Nolte, Alexander and Pe-Than, Ei Pa Pa and Filippova, Anna and Bird, Christian and Scallen, Steve and Herbsleb, James D},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={2},
  number={CSCW},
  pages={129},
  year={2018},
  publisher={ACM}
}

@inproceedings{amershi2018se4ml,
title={{Software Engineering for Machine Learning: A Case Study}},
author={Saleema Amershi and Andrew Begel and Christian Bird and Robert DeLine and Harald Gall 
	and Ece Kamar and Nachiappan Nagappan and Besmira Nushi and Thomas Zimmermann},
booktitle={Proceedings of the International Conference on Software Engineering (Software Engineering In Practice Track)},
year={2019},
publisher={IEEE}
}

@article{than2018designing,
  title={{Designing Corporate Hackathons With a Purpose}},
  author={Than, Ei Pa Pa Pe and Nolte, Alexander and Filippova, Anna and Bird, Christian and Scallen, Steve and Herbsleb, James},
  journal={IEEE Software},
  year={2018},
  month={Early Access},
  publisher={IEEE}
}


@ARTICLE{devanbu2018belief,
author = {P. Devanbu and T. Zimmermann and C. Bird},
journal = {IEEE Software},
title = {{Belief and Evidence: How Software Engineers Form Their Opinions}},
year = {2018},
volume = {35},
number = {6},
pages = {72-76},
keywords={Software development;Software engineering},
doi = {10.1109/MS.2018.4321246},
url = {doi.ieeecomputersociety.org/10.1109/MS.2018.4321246},
ISSN = {0740-7459},
month={November/December}
}


@inproceedings{hellendoorn2018deep,
  title={{Deep learning type inference}},
  author={Hellendoorn, Vincent J and Bird, Christian and Barr, Earl T and Allamanis, Miltiadis},
  booktitle={Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages={152--162},
  year={2018},
  organization={ACM}
}

@ARTICLE{allamanis2018loopidioms, 
	author={Allamanis, Miltiadis and Barr, Earl and Bird, Christian and Devanbu, Premkumar and Marron, Mark and Sutton, Charles},
	title = {{Mining Semantic Loop Idioms from Big Code}},
	journal={{IEEE Transactions on Software Engineering}}, 
	year={2018}, 
}

@inproceedings{henley2018cfar,
  title={CFar: A Tool to Increase Communication, Productivity, and Review Quality in Collaborative Code Reviews},
  author={Henley, Austin Z and Mu{\c{c}}lu, KIvan{\c{c}} and Christakis, Maria and Fleming, Scott D and Bird, Christian},
  booktitle={Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  pages={157},
  year={2018},
  organization={ACM}
}

@ARTICLE{kalliamvakou2018managers, 
	author={Eirini Kalliamvakou and Christian Bird and Thomas Zimmermann and Andrew Begel and Robert DeLine and Daniel M. German},
	title = {{What Makes a Great Manager of Software Engineers?}},
	journal={{IEEE Transactions on Software Engineering}}, 
	year={2018}, 
}

@inproceedings{ford2017personas,
	author = {Denae Ford and Thomas Zimmermann and Christian Bird and Nachiappan Nagappan},
	title = {{Characterizing Software Engineering Work with Personas Based on Knowledge Worker Actions}},
	Booktitle={{Proceedings of the International Symposium on Empirical Software Engineering and Measurement}},
	year={2017},
	publisher={ACM/IEEE}
}

@article{macleod2018codereviewing,
	author = {Laura Macleod and Michaela Greiler and Margaret-Anne Storey
		and Christian Bird and Jacek Czerwonka},
	title={{Code Reviewing in the Trenches: Understanding Challenges,
		Best Practices, and Tool Needs}},
	journal={{IEEE Software}},
	publisher={IEEE Computer Society},
	postdate={4-20-2013},
	year={2017}
}

@inproceedings{gao2017javascript,
	Author = {Zheng Gao and Christian Bird and Earl T. Barr},
	Title = {{To Type or not to Type: On the Effectiveness of Static typing for JavaScript}},
	booktitle = {{Proceedings of the 39th International Conference on Software Engineering}},
	year	= {2017},
	acceptance = {16\%},
	publisher = {{IEEE}}
}

@incollection{bird2016interviews,
    Author = {Christian Bird},
    Editor = {Tim Menzies and Laurie Williams and Thomas Zimmermann},
    bookTitle = {{Perspectives on Data Science for Software Engineering}},
    Publisher = {Morgan Kaufmann},
    title = {{Interviews}},
    Year = {2016}
}

@incollection{bird2016bias,
    Author = {Christian Bird},
    Editor = {Tim Menzies and Laurie Williams and Thomas Zimmermann},
    bookTitle = {{Perspectives on Data Science for Software Engineering}},
    Publisher = {Morgan Kaufmann},
    title = {{Don't embarrass yourself: Beware of bias in your data}},
    Year = {2016}
}

@inproceedings{christakis2016developers,
  title={What developers want and need from program analysis: an empirical study},
  author={Christakis, Maria and Christian Bird},
  booktitle={Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
  pages={332--343},
  year={2016},
  organization={ACM}
}

@inproceedings{smith2016beliefs,
  title={Beliefs, practices, and personalities of software engineers: a survey in a large software company},
  author={Smith, Edward K and Christian Bird and Zimmermann, Thomas},
  booktitle={{Proceedings of the 9th International Workshop on Cooperative and Human Aspects of Software Engineering}},
  pages={15--18},
  year={2016},
  organization={ACM}
}


@ARTICLE{bosu2017review, 
	author={Amiangshu Bosu and Jeffrey C. Carver and Christian Bird and Jonathan Orbeck and Chris Chockley}, 
	journal={{IEEE Transactions on Software Engineering}}, 
	title={{Process Aspects and Social Dynamics of Contemporary Code Review: Insights from Open Source Development and Industrial Practice at Microsoft}}, 
	year={2017}, 
	keywords={Collaboration;Context;Human factors;Inspection;Instruments;Measurement;Organizations;Code Review;Commercial projects;OSS;Open Source;Peer impressions;Survey}, 
	doi={10.1109/TSE.2016.2576451}, 
	ISSN={0098-5589}, 
	month={},
}

@inproceedings{washburn2016games,
author = {Michael Washburn and Pvithra Sathiyanarayanan and Meiyappan Nagappan
	and Thomas Zimmermann and Christian Bird},
title = {{What Went Right and What Went Wrong: 
	An Analysis of 155 Postmortems from Game Development}},
booktitle = {{Proceedings of the 38th International Conference on Software Engineering (Software Engineering in Practice Track)}},
year	= {2016},
  acceptance = {26\%},
publisher = {{ACM}}
}

%this is a comment

@inproceedings{devanbu2016evidence,
author = {Premkumar Devanbu and Thomas Zimmermann and Christian Bird},
title = {{Belief and Evidence in Empirical Software Engineering}},
booktitle = {{Proceedings of the 38th International Conference on Software Engineering}},
year	= {2016},
acceptance = {19\%},
publisher = {{ACM}}
}

@inproceedings{manotas2016green,
author = {Irene Manotas and Christian Bird and Rui Zhang and
 David Shepherd and Will Snipes and Ciera Jaspan and 
 Caitlin Sadowski and Lori Pollock and James Clause},
title = {{An Empirical Study of Practitioners' Perspectives
 on Green Software Engineering}},
booktitle = {{Proceedings of the 38th International Conference on Software Engineering}},
year	= {2016},
acceptance = {19\%},
publisher = {{ACM}},
abstract = {The energy consumption of software is an increasing concern
as the use of mobile applications, embedded systems, and
data center-based services expands. While research in green
software engineering is correspondingly increasing, little is
known about the current practices and perspectives of software
engineers in the field. This paper describes the first
empirical study of how practitioners think about energy when
they write requirements, design, construct, test, and maintain
their software. We report findings from a quantitative,
targeted survey of 464 practitioners from ABB, Google, IBM,
and Microsoft, which was motivated by and supported with
qualitative data from 18 in-depth interviews with Microsoft
employees. The major findings and implications from the
collected data contextualize existing green software engineering
research and suggest directions for researchers aiming to
develop strategies and tools to help practitioners improve
the energy usage of their applications.}
}



@article{zanjani2016recommending,
  author    = {Motahareh Bahrami Zanjani and Huzefa Kagdi and Christian Bird},
  title     = {{Automatically Recommending Peer Reviewers in Modern Code Review}},
  journal   = {{IEEE} Transactions on Software Engineering},
  year={2016}, 
  volume={42}, 
  number={6}, 
  pages={530-543}, 
  short_venue = {TSE},
  postdate = {1-15-2015},
  publisher = {{IEEE}},
  month={June},
}



@book{bird2015artandscience,
	title = {{The Art and Science of Analyzing Software Data}},
	editor = {Christian Bird and Tim Menzies and Thomas Zimmermann},
	author = {{foo}},
	year = {2015},
	publisher = {Morgan Kauffman}
}

@inproceedings{saraiva2015ngram,
  author = {Juliana Saraiva and Christian Bird and Thomas Zimmermann},
  title = {{Products, Developers, and Milestones: How Should I Build My N-Gram Language Model}},
  booktitle = {Proceedings of the the joint meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software	Engineering (ESEC/FSE) Industry Track},
  year = {2015},
  acceptance = {33\%},
  publisher = {{ACM}}
}

@inproceedings{allamanis2015suggesting,
  author = {Miltiadis Allamanis and Earl T. Barr and Christian Bird and Charles Sutton},
  title = {{Suggesting Accurate Method and Class Names}},
  booktitle = {Proceedings of the the joint meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software	Engineering (ESEC/FSE)},
  year = {2015},
  acceptance = {25\%},
  publisher = {{ACM}}
}

@inproceedings{ray2015uniqueness,
	author = {Baishakhi Ray and Meiyappan Nagappan and Christian Bird and Nachiappan Nagappan and Thomas Zimmermann},
	title = {{The Uniqueness of Changes: Characteristics and Applications}},
	booktitle = {Proceedings of the International Conference on Mining Software Repositories},
	short_venue = {MSR 2015},
	publisher = {{IEEE}},
	year = {2015},
	postdate = {3-4-2015},
    	acceptance = {30\%},
	abstract = {
		Changes in software development come in many forms. Some changes are frequent, idiomatic, or repetitive e.g. adding checks for nulls or logging important values) while others are unique. We hypothesize that unique changes are different from the more common similar (or non-unique) changes in important ways; they may require more expertise or represent code that is more complex or prone to mistakes. As such, these unique changes are worthy of study. In this paper, we present a definition of unique changes and provide a method for identifying them in software project history. Based on the results of applying our technique on the Linux kernel and two large projects at Microsoft, we present an empirical study of unique changes. We explore how prevalent unique changes are and investigate where they occur along the architecture of the project. We further investigate developers' contribution towards uniqueness of changes. We also describe potential applications of leveraging the uniqueness of change and implement two of those applications, evaluating the risk of changes based on uniqueness and providing change recommendations for non-unique changes.}

}


@inproceedings{bird2015cfa,
	author = {Christian Bird and Trevor Carnahan and Michaela Greiler},
	title = {{Lessons Learned from Building and Deploying a Code Review Analytics Platform}},
	booktitle = {Proceedings of the International Conference on Mining Software Repositories},
	publisher = {{IEEE}},
	short_venue = {MSR 2015},
    	acceptance = {30\%},
	year = {2015},
	postdate = {3-4-2015},
	abstract = {Tool-based code review is growing in popularity and has become a standard part of the development process at Microsoft. Adoption of these tools makes it possible to mine data from code reviews and provide access to it. In this paper, we present an experience report for CodeFlow Analytics, a system that collects code review data, generates metrics from this data, and provides a number of ways for development teams to access the metrics and data. We discuss the design, design decisions and challenges that we encountered when building CodeFlow Analytics. We contacted teams that used CodeFlow Analytics over the past two years and discuss what prompted them to use CodeFlow Analytics, how they have used it, and what the impact has been. Further, we survey research that has been enabled by using the CodeFlow Analytics platform. We provide a series of lessons learned from this experience to help others embarking on a task of building an analytics platform in an enterprise setting.
	}
}

@inproceedings{bosu2015useful,
	author = {Amiangshu Bosu and Michaela Greiler and Christian Bird},
	title = {{Characteristics of Useful Code Reviews: An Empirical Study at Microsoft}},
	booktitle = {Proceedings of the International Conference on Mining Software Repositories},
	publisher = {{IEEE}},
	short_venue = {MSR 2015},
	year = {2015},
    	acceptance = {30\%},
	postdate = {3-4-2015},
	abstract = {Over the past decade, both open source and commercial
software projects have adopted contemporary peer code
review practices as a quality control mechanism. Prior research
has shown that developers spend a large amount of time and
effort performing code reviews. Therefore, identifying factors that
lead to useful code reviews can benefit projects by increasing
code review effectiveness and quality. In a three-stage mixed
research study, we qualitatively investigated what aspects of
code reviews make them useful to developers, used our findings
to build and verify a classification model that can distinguish
between useful and not useful code review feedback, and finally
we used this classifier to classify review comments enabling us
to empirically investigate factors that lead to more effective code
review feedback.
<br>
In total, we analyzed 1.5 millions review comments from five
Microsoft projects and uncovered many factors that affect the
usefulness of review feedback. For example, we found that the
proportion of useful comments made by a reviewer increases
dramatically in the first year that he or she is at Microsoft but
tends to plateau afterwards. In contrast, we found that the more
files that are in a change, the lower the proportion of comments
in the code review that will be of value to the author of the
change. Based on our findings, we provide recommendations for
practitioners to improve effectiveness of code reviews.
}
}

@inproceedings{zanjani2015developer,
	author = {Motahareh Bahrami Zanjani and Huzefa Kagdi and Christian Bird},
	title = {{Using Developer-Interaction Trails to Triage Change Requests}},
	booktitle = {Proceedings of the International Conference on Mining Software Repositories},
	publisher = {{IEEE}},
	year = {2015},
	short_venue = {MSR 2015},
	postdate = {3-4-2015},
    	acceptance = {30\%},
	abstract = {
		The paper presents an approach, namely iHDev,
to recommend developers who are most likely to implement
incoming change requests. The basic premise of iHDev is that
the developers who interacted with the source code relevant to
a given change request are most likely to best assist with its
resolution. A machine-learning technique is first used to locate
source-code entities relevant to the textual description of a given
change request. iHDev then mines interaction trails (i.e., Mylyn
sessions) associated with these source-code entities to recommend
a ranked list of developers. iHDev integrates the interaction trails
in a unique way to perform its task, which was not investigated
previously.
<br>
An empirical study on open source systems Mylyn and Eclipse
Project was conducted to assess the effectiveness of iHDev. A
number of change requests were used in the evaluated benchmark.
Recall for top one to five recommended developers and
Mean Reciprocal Rank (MRR) values are reported. Furthermore,
a comparative study with two previous approaches that use
commit histories and/or the source-code authorship information
for developer recommendation was performed. Results show
that iHDev could provide a recall gain of up to 127.27\% with
equivalent or improved MRR values by up to 112.5\%.
	}
}

@inproceedings{smith2015homegrown,
    author = {Edward K. Smith and Christian Bird and Thomas Zimmermann},
    title = {{Build it yourself!  Homegrown Tools in a Large Software Company}},
    booktitle = {Proceedings of the 37th International Conference on Software Engineering},
    year = {2015},
    short_venue = {ICSE 2015},
    publisher = {{IEEE}},
    acceptance = {19\%},
    postdate = {1-20-2015},
    abstract = {Developers sometimes take the initiative to build tools to solve problems 
	    they face. What motivates developers to build these tools? What is the value for a company? 
	    Are the tools built useful for anyone besides their creator? We conducted a qualitative study 
	    of tool building, adoption, and impact within Microsoft. This paper presents our findings 
	    on the extrinsic and intrinsic factors linked to toolbuilding, the value of building tools, 
	    and the factors associated with tool spread. We find that the majority of developers build tools. 
	    While most tools never spread beyond their creator's team, most have more than one user, and 
	    many have more than one collaborator. Organizational cultures that are receptive towards 
	    toolbuilding produce more tools, and more collaboration on tools. When nurtured and spread, 
	    homegrown tools have the potential to create significant impact on organizations.
    }
    
}

@inproceedings{barnett2015helping,
    author = {Michael Barnett and Christian Bird and Joao Brunet and Shuvendu K. Lahiri},
    title = {{Helping Developers Help Themselves: Automatic Decomposition of Code Review Changesets}},
    booktitle = {Proceedings of the 37th International Conference on Software Engineering},
    year = {2015},
    publisher = {{IEEE}},
    short_venue = {ICSE 2015},
    postdate = {1-20-2015},
    acceptance={19\%},
    abstract = {Code Reviews, an important and popular mechanism
for quality assurance, are often performed on a changeset,
a set of modified files that are meant to be committed to a
source repository as an atomic action. Understanding a code
review is more difficult when the changeset consists of multiple,
independent, code differences. We introduce ClusterChanges,
an automatic technique for decomposing changesets and evaluate
its effectiveness through both a quantitative analysis and a
qualitative user study.}

}

@article{murphyhill2015design,
  author    = {Emerson Murphy-Hill and Thomas Zimmermann and Christian Bird and Nachiappan Nagappan},
  title     = {{The Design Space of Bug Fixes and How Developers Navigate It}},
  journal   = {{IEEE} Transactions on Software Engineering},
  year      = {2015},
  short_venue = {TSE},
  postdate = {1-15-2015},
  publisher = {{IEEE}},
  abstract = {When software engineers fix bugs, they may have several options as to how to fix those bugs. Which fix they
choose has many implications, both for practitioners and researchers: What is the risk of introducing other bugs during the fix?
Is the bug fix in the same code that caused the bug? Is the change fixing the cause or just covering a symptom? In this paper,
we investigate alternative fixes to bugs and present an empirical study of how engineers make design choices about how to fix
bugs. We start with a motivating case study of the Pex4Fun environment. Then, based on qualitative interviews with 40
engineers working on a variety of products, data from 6 bug triage meetings, and a survey filled out by 326 Microsoft engineers
and 37 developers from other companies, we found a number of factors, many of them non-technical, that influence how bugs
are fixed, such as how close to release the software is. We also discuss implications for research and practice, including how to
make bug prediction and localization more accurate.}

}


@inproceedings{allamanis2014learning,
	Author={Miltiadis Allamanis and Earl T. Barr and Christian Bird and Charles Sutton},
	Title={{Learning Natural Coding Conventions}},
	Booktitle = {Proceedings of the 22nd International Symposium on Foundations of Software Engineering},
	Year={2014},
	short_venue = {FSE 2014},
	acceptance={22\%},
	Publisher = {ACM},
	Award = {ACM SigSoft Distinguished Paper},
	postdate = {7-3-2014},
	abstract = {Every programmer has a characteristic style, ranging from preferences
about identifier naming to preferences about object relationships
and design patterns. Coding conventions define a consistent
syntactic style, fostering readability and hence maintainability.
When collaborating, programmers strive to obey a projects coding
conventions. However, one third of reviews of changes contain
feedback about coding conventions, indicating that programmers
do not always follow them and that project members care deeply
about adherence. Unfortunately, programmers are often unaware of
coding conventions because inferring them requires a global view,
one that aggregates the many local decisions programmers make
and identifies emergent consensus on style. We present NATURALIZE,
a framework that learns the style of a codebase, and suggests
revisions to improve stylistic consistency. NATURALIZE builds on
recent work in applying statistical natural language processing to
source code. We apply NATURALIZE to suggest natural identifier
names and formatting conventions. We present four tools focused on
ensuring natural code during development and release management,
including code review. NATURALIZE achieves 94\% accuracy in
its top suggestions for identifier names. We used NATURALIZE to
generate 18 patches for 5 open source projects: 14 were accepted.
	}
}

@inproceedings{gupta2014energy,
	Author={Ashish Gupta and Thomas Zimmermann and Christian Bird and Nachiappan Nagappan and Thirumalesh Bhat and Syed Emran},
	Title={{Mining Energy Traces to Aid in Software Development: An Empirical Case Study}},
	Booktitle={Proceedings of the International Symposium on Empirical Software Engineering and Measurement},
	Year={2014},
	postdate={6-15-2014},
	Publisher={ACM/IEEE}
}


@inproceedings{bird2014rac,
	Author={Christian Bird and Venkatesh Prasad Ranganath and Thomas Zimmermann and Nachiappan Nagappan and Andreas Zeller},
	Title={Extrinsic Influence Factors in Software Reliability: A Study of 200,000 Windows Machines},
	Booktitle={Proceedings of the International Conference on Software Engineering (SEIP Track)},
	Year={2014},
	acceptance={21\%},
	postdate={3-10-2014},
	Publisher = {IEEE}
}

@inproceedings{phillips2014build,
	Author={Shaun Phillips and Thomas Zimmermann and Christian Bird},
	Title={{Understanding and Improving Software Build Teams}},
	Booktitle={Proceedings of the International Conference on Software Engineering},
	Year={2014},
	acceptance = {20\%},
	postdate={1-20-2014},
	Publisher = {IEEE}
}

%KCNJ

@inproceedings{muslu2014dvcs,
	Author={Kivan\c{c} Mu\c{s}lu and Christian Bird and Nachiappan Nagappan and Jacek Czerwonka},
	Title={{Transition from Centralized to Decentralized Version Control Systems: A Case Study on Reasons, Barriers, and Outcomes}},
	Booktitle={Proceedings of the International Conference on Software Engineering},
	Year={2014},
	acceptance = {20\%},
	postdate={1-20-2014},
	Publisher = {IEEE}
}

@inproceedings{nagappan2013diversity,
	Author = {Meiyappan Nagappan and Thomas Zimmermann and Christian Bird},
	Title = {Diversity in Software Engineering Research},
	Booktitle = {Proceedings of the the joint meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering (ESEC/FSE)},
	Year = {2013},
	Acceptance = {20\%},
	postdate={6-21-2013},
	Publisher = {ACM}
}

@inproceedings{rigby2013convergent,
	Author = {Peter C. Rigby and Christian Bird},
	Title = {Convergent Software Peer Review Practices},
	Booktitle = {Proceedings of the the joint meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering (ESEC/FSE)},
	Year = {2013},
	Acceptance = {20\%},
	postdate={6-22-2013},
	Publisher = {ACM}
}

@inproceedings{murphy2013agile,
    Author = {Brendan Murphy and Christian Bird and Thomas Zimmermann
    	and Laurie Williams and Nachiappan Nagappan and Andrew Begel},
    Title = {{Have Agile Techniques been the Silver Bullet for Software Development at Microsoft}},
    Booktitle = {Proceedings of the Seventh International Symposium on Empirical Software Engineering and Measurement},
    Year = {2013},
    Acceptance = {28\%},
    postdate = {7-12-2013},
    Publisher = {ACM/IEEE}
}

@inproceedings{barr2013shapes,
	title = {{Collecting a Heap of Shapes}},
	author = {Earl T. Barr and Christian Bird and Mark Marron},
	booktitle = {Proceedings of the International Symposium on Software Testing and Analysis},
	year = {2013},
	acceptance = {25\% Best Paper Award 2\%},
	postdate={4-10-2013},
	award = {ACM Distinguished Paper Award},
	publisher = {ACM}
}


@article{musson2013software,
	author = {Robert Musson and Jacqueline Richards and Danyel Fisher and Christian Bird and Brian Bussone and Sandipan Ganguly},
	title={{Leveraging the Crowd: How 48,000 Users Helped Improve Lync Performance}},
	journal={{IEEE Software}},
	publisher={IEEE Computer Society},
	postdate={4-20-2013},
	year={2013}
}

@inproceedings{harper2013ecscw,
	author={Richard Harper and Christian Bird and Thomas Zimmermann and Brendan Murphy},
	Title={{Dwelling in Software: aspects of the felt-life of engineers in large software projects}},
	Booktitle = {Proceedings of the European Conference on Computer-Supported Cooperative Work},
	Year={2013},
	postdate={9-12-2013}
}

@inproceedings{rigby2013releng,
	Author={Peter C. Rigby and Earl T. Barr and Christian Bird and Premkumar Devanbu and Daniel M. German},
	Title={{What Effect does Distributed Version Control have on OSS Project Organization}},
	Booktitle={Proceedings of the International Workshop on Release Engineering},
	Year={2013},
	postdate={3-12-2013},
	Publisher = {IEEE}
}

@inproceedings{smith2013chase,
	Author={Edward Smith and Robert Loftin and Emerson Murphy-Hill and Christian Bird and Thomas Zimmermann},
	Title={{Improving Developer Participation Rates in Surveys}},
	Booktitle={Proceedings of the International Workshop on Cooperative and Human Aspects of Software Engineering},
	Year={2013},
	postdate={3-13-2013},
	Publisher = {IEEE}
}

@inproceedings{kocaguneli2013distributed,
	Title = {Distributed Development Considered Harmful?},
	Author = {Ekrem Kocaguneli and Thomas Zimmermann and Christian Bird
		and Nachiappan Nagappan and Tim Menzies},
	Booktitle = {Proceedings of the International Conference on 
		Software Engineering (Software Engineering in Practice Track)},
	Publisher = {IEEE},
	acceptance = {20\%},
	Year = {2013},
	postdate = {2-10-2013}
}


@inproceedings{mukadam2013gerrit,
	Author={Murtuza Mukadam and Christian Bird and Peter C. Rigby},
	Title = {Gerrit Software Code Review Data from Android},
	Booktitle = {Proceedings of the International Working Conference on Mining Software Repositories (Data Track)},
	Publisher = {IEEE},
	postdate={3-20-2013},
	Year={2013}
}



@inproceedings{murphyhill2013dbf,
	Author={Emerson Murphy-Hill and Thomas Zimmermann and Christian Bird and Nachiappan Nagappan},
	Title={The Design of Bug Fixes},
	Booktitle={Proceedings of the International Conference on Software Engineering},
	Year={2013},
	acceptance = {18\%},
	postdate={1-20-2013},
	Publisher = {IEEE}
}

@inproceedings{bacchelli2013eoc,
	Author={Alberto Bacchelli and Christian Bird},
	Title={Expectations, Outcomes, and Challenges of Modern Code Review},
	Booktitle={Proceedings of the International Conference on Software Engineering},
	Year={2013},
	postdate={1-20-2013},
	acceptance = {18\% nominated for Distinguished Paper 4\%},
	Publisher = {IEEE}
}

@article{parnin2012auj,
    Author = {Chris Parnin and Christian Bird and Emerson Murphy-Hill},
    Title = {{Adoption and Use of Java Generics}},
    Journal = {Empirical Software Engineering},
    Publisher = {Springer-Verlag},
    Year = {2012},
    postdate={12-6-2012},
    Pages = {1-43}
}

@Article {hindle2014topics,
abstract     = {Large organizations like Microsoft tend to rely on formal requirements
                documentation in order to specify and design the software products that they
                develop. These documents are meant to be tightly coupled with the actual
                implementation of the features they describe. In this paper we evaluate the value
                of high-level topic-based requirements traceability and issue report traceability
                in the version control system, using <em>Latent Dirichlet Allocation</em> (LDA).
                We evaluate LDA topics on practitioners and check if the topics and trends
                extracted match the perception that industrial Program Managers and Developers
                have about the effort put into addressing certain topics. We then replicate this
                study again on Open Source Developers using issue reports from issue trackers
                instead of requirements, confirming our previous industrial conclusions. We found
                that efforts extracted as commits from version control systems relevant to a
                topic often matched the perception of the managers and developers of what
                actually occurred at that time. Furthermore we found evidence that many of the
                identified topics made sense to practitioners and matched their perception of
                what occurred. But for some topics, we found that practitioners had difficulty
                interpreting and labelling them. In summary, we investigate the high-level
                traceability of requirements topics and issue/bug report topics to version
                control commits via topic analysis and validate with the actual stakeholders the
                relevance of these topics extracted from requirements and issues.},
author       = {Abram Hindle and Christian Bird and Thomas Zimmermann and Nachiappan Nagappan},
abbrv = {ESE},
pages = {1-37},
journal      = {Empirical Software Engineering},
month        = {June},
publisher    = {Springer},
title        = {Do Topics Make Sense to Managers and Developers?},
url          = {http://research.microsoft.com/apps/pubs/default.aspx?id=228976},
year         = {2014}
}

@inproceedings{hindle2012rri,
	Author = {Abram Hindle and Christian Bird and Thomas Zimmermann and Nachiappan Nagappan},
	Title = {Relating Requirements to Implementation via Topic Analysis: Do Topics Extracted from Requirements Make Sense to Managers and Developers?},
	Booktitle = {Proceedings of the 28th IEEE International Conference on Software Maintenance},
	Year = {2012},
	postdate={6-3-2012},
	Acceptance = {25\%},
	Publisher = {IEEE}
}

@inproceedings{bird2012avb,
	Author = {Christian Bird and Thomas Zimmermann},
	Title = {Assessing the Value of Branches with What-if Analysis},
	Booktitle = {Proceedings of the 20th International Symposium on Foundations of Software Engineering},
	Year = {2012},
	postdate={6-20-2012},
	Acceptance = {17\% ACM Distinguished Paper Award},
	award = {ACM Distinguished Paper Award},
	Publisher = {ACM}
}

@inproceedings{shihab2012ebs,
    Author = {Emad Shihab and Christian Bird and Thomas Zimmermann},
    Title = {The Effect of Branching Strategies on Software Quality},
    Booktitle = {Proceedings of the Sixth International Symposium on Empirical Software Engineering and Measurement},
    Year = {2012},
    postdate={7-10-2012},
    Acceptance = {25\%},
    Publisher = {ACM/IEEE},
}

@inproceedings{bird2012www,
    Author = {Christian Bird and Nachiappan Nagappan},
    Title = {Who? Where? What? Examining Distributed Development in Two Large Open Source Projects},
    Booktitle = {Proceedings of the International Working Conference on Mining Software Repositories},
    Year = {2012},
    postdate={3-18-2012},
    Acceptance = {28\%},
    Publisher = {IEEE},
}


@inproceedings{zimmermann2012ccs,
    Author = {Thomas Zimmermann and Christian Bird},
    Title = {{Collaborative Software Development in Ten Years: Diversity, Tools, and Remix Culture}},
    Booktitle = {Proceedings of the Workshop on The Future of Collaborative Software Development},
    postdate={2-3-2012},
    Year = {2012},
}

@article{rahman2012cwt,
    Author = {Foyzur Rahman and Christian Bird and Premkumar Devanbu},
    Title = {{Clones: What \textbf{is} that Smell?}},
    Journal = {Empirical Software Engineering, An International Journal},
    Publisher = {Springer-Verlag},
    issn = {1382-3256},
    Year = {2012},
    postdate={12-11-2011},
    url = {http://dx.doi.org/10.1007/s10664-011-9195-3}
}

@inproceedings{barr2012cid,
	Author = {Earl T. Barr and Christian Bird and
		Peter C. Rigby and Abram Hindle and Daniel M. German
			and Premkumar Devanbu},
	Title = {{Cohesive and Isolated Development with Branches}},
	Year = {2012},
	Booktitle = {{Proceedings of the International Conference on 
		Fundamental Approaches to Software Engineering}},
	Publisher = {Springer},
	postdate={1-10-2012},
	Acceptance = {24\%}
}

@inproceedings{menzies2011ise,
	Author = {Tim Menzies and Christian Bird and 
		Tom Zimmermann and Wolfram Schulte and Ekrem Kocaguneli},
	Title = {{The Inductive Software Engineering Manifesto: Principles for Industrial Data Mining}},
	booktitle = {{Proceedings of the International Workshop on Machine Learning Technologies in Software Engineering}},
	year = {2011},
	postdate={10-23-2011},
	publisher = {ACM}
}



@inproceedings{bird2011scc,
	Author = {Christian Bird},
	title = {{Sociotechnical Coordination and Collaboration in Open Source Software}},
	booktitle = {{Doctoral Symposium, Proceedings of the 27th IEEE International Conference on Software Maintenance}},
	year = {2011},
	location = {Williamsburg, VA, USA},
	abbrv = {ICSM 11},
	publisher = {IEEE},
	postdate={7-10-2011},
}

@inproceedings{zeller2011ffl,
	Author = {Andreas Zeller and Thomas Zimmermann and Christian Bird},
	title = {{Failure is a Four Letter Word: A Parody in Empirical Research}},
	booktitle = {{Proceedings of the 7th International Conference on Predictor
		Models in Software Engineering}},
	year = {2011},
	Location = {Banff, Canada},
	postdate={7-13-2011}
}


@inproceedings{hong2011uds,
	Author = {Qiaona Hong and Sunghun Kim and S. C. Cheung and Christian Bird},
	title = {{Understanding a Developer Social Network and its Evolution}},
	booktitle = {Proceedings of the 27th IEEE International Conference on Software Maintenance},
	Year = {2011},
	Acceptance = {28\%},
	abbrv = {ICSM 11},
	publisher = {IEEE},
	Location = {Williamsburg, VA, USA}
}


@inproceedings{bird2011dtm,
	Author = {Christian Bird and Nachiappan Nagappan and Brendan Murphy and Harald Gall and Premkumar Devanbu},
	Booktitle = {Proceedings of the the eighth joint meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering},
	Location = {Szeged, Hungary},
	Title = {{Don't Touch My Code! Examining the Effects of Ownership on Software Quality} },
	Year = {2011},
	acceptance = {17\%},
	publisher = {ACM},
	abbrv = {ESEC/FSE 11},
	pdf = {bird2011dtm.pdf},
	abstract = {Ownership is a key aspect of large-scale software 
development. We examine the relationship between different 
ownership measures and software failures in two large software
projects: Windows Vista and Windows 7. We find that in all
cases, measures of ownership such as the number of
low-expertise developers, and the proportion of ownership
for the top owner have a relationship with both pre-release
faults and post-release failures. We also empirically identify 
reasons that low-expertise developers make changes to
components and show that the removal of low-expertise 
contributions dramatically decreases the performance of 
contribution based defect prediction. Finally we provide 
recommendations for source code change policies and utilization
of resources such as code inspections based on our results.}
}


@inproceedings{parnin2011jga,
   Author = {Chris Parnin and Christian Bird and Emerson Murphy-Hill},
   Title = {{Java Generics Adoption: How New Features are Introduceded, Champion, or Ignored}},
   BookTitle = {Proceedings of the International Working Conference on Mining Software Repositories},
   Year = {2011},
   pdf = {parnin2011jga},
   acceptance = {33\%, invited to Journal special issue: 10\%},
   Abstract = {
Support for generic programming was added to the Java language in 2004,
representing perhaps the most significant change to one of the most widely used
programming lan- guages today. Researchers and language designers antici- pated
this this addition would relieve many long-standing problems plaguing
developers, but surprisingly, no one has yet measured whether generics actually
provide such relief. In this paper, we report on the first empirical
investigation into how Java generics have been integrated into open source
software by automatically mining the history of 20 popular open source Java
programs, traversing more than 500 million lines of code in the process. We
evaluate five hypotheses, each based on assertions made by prior researchers,
about how Java developers use generics. For example, our results suggest that
generics do not significantly reduce the number of type casts and that generics
are usually adopted by a single champion in a project, rather than all
committers.},

}

@inproceedings{bird2011tbg,
    Author = {Christian Bird and Thomas Zimmermann and Alex Teterev},
    Title = {{A Theory of Branches as Goals and Virtual Teams}},
    Booktitle = {Proceedings of the International Workshop on Cooperative and Human Aspects of Software Engineering},
    Year = {2011},
    pdf = {bird2011tbg.pdf},
    Abstract = {
	A common method of managing the complexity of both technical and organizational
	relationships in a large software project is to use branches within the source
	code management system to partition the work into teams and tasks. We claim
	that the files modified on a branch are changed together in a cohesive way to
	accomplish some task such as adding a feature, fixing a related set of bugs, or
	implementing a subsystem, which we collectively refer to as the goal of the
	branch. Further, the developers that work on a branch represent a virtual team.
	In this paper, we develop a theory of the relationship between goals and
	virtual teams on different branches. Due to expertise, ownership, and awareness
	concerns, we expect that if two branches have similar goals, they will also
	have similar virtual teams or be at risk for communication and coordination
	breakdowns with the accompanying negative effects. In contrast, we do not
	expect the converse to always be true. In the first step towards an actionable
	result, we have evaluated this theory empirically on two releases of the
	Windows operating system and found support in both.
    }
}

@inproceedings{barr2010sg,
    Author = {Earl Barr and Christian Bird and Eric Hyatt and Tim Menzies and Gregorio Robles},
    Title = {{On the Shoulders of Giants}},
    Booktitle = {{FSE/SDP Workshop on the Future of Software Engineering Research}},
    Year = {2010},
    acceptance = {65\%},
    pdf = {barr2010sg.pdf},
    Abstract = {

    Science rests on peer review and the wide-spread dissemination of
        knowledge.  Software engineering research will advance further and
        faster if the sharing of data and tools were easier and more
        wide-spread.  Pragmatic concerns hinder the realization of this ideal:
        the time and effort required and the risk of being scooped.  We examine
        the costs and benefits of facilitating sharing in our field in an
        effort to help the community understand what problems exist and find a
        solution.  We examine how other fields, such as medicine and physics,
    handle sharing, describe the value of sharing for replication and
        innovation, and address practical concerns such as standards and
        warehousing.  To launch what we hope will become an ongoing discussion
        of solutions in our community, we present some ways forward that
        mitigate the risk of sharing --- partial sharing, registry, escrow, and
        market.
    }
}

@inproceedings{bird2010lee,
    Author = {Christian Bird and Adrian Bachmann and Foyzur Rahman and Abraham Bernstein},
    Title = {{Linkster: Enabling Efficient Manual Mining}},
    Booktitle = {Demonstration Track, Proceedings of the 17th SIGSOFT Symposium on Foundations of Software Engineering},
	Publisher = {ACM},
	Year = {2010},
	acceptance = {accepted for formal demonstration, 21\%},
	abbrv = {FSE 10},
    pdf = {bird2010lee.pdf},
    Abstract = {

    While many uses of mined software engineering data are automatic in nature,
    some techniques and studies either require, or can be improved, by manual
    methods.  Unfortunately, manually inspecting, analyzing, and annotating
    mined data can be difficult and tedious, especially when information
    from multiple sources must be integrated.  Oddly, while there are
    numerous tools and frameworks for automatically mining and analyzing
    data, there is a dearth of tools which facilitate manual methods.  To
    fill this void, we have developed Linkster, a tool which integrates
    data from bug databases, source code repositories, and mailing list
    archives to allow manual inspection and annotation.  Linkster has
    already been used successfully by an OSS project lead to obtain data
    for one empirical study.

    }
}

@inproceedings{bird2011ese,
	Author = {Christian Bird and Brendan Murphy and Nachiappan Nagappan and Thomas Zimmermann},
	title = {{Empirical Software Engineering at Microsoft Research}},
	Booktitle = {Showcase Track, Proceedings of the ACM Conference on Computer Supported Cooperative Work},
	Publisheer = {ACM},
	year = {2011}
}

@incollection{bird2010cc,
    Author = {Christian Bird},
    Editor = {Andy Oram and Greg Wilson},
    bookTitle = {{Making Software: What Really Works, and Why We Believe It}},
    Publisher = {O'Reilly},
    title = {{Conway's Corollary}},
    Year = {2010},
    Link = {http://books.google.com/books?id=DxuGi5h2-HEC&lpg=PA205&ots=0VqzngTdqU&dq=making\%20software\%20conway's\%20corollary&pg=PA187#v=onepage&q=making\%20software\%20conway's\%20corollary&f=false}
}

@inproceedings{bachmann2010mlb,
    Author = {Adrian Bachmann and Christian Bird and Foyzur Rahman and 
        Premkumar Devanbu and Abraham Bernstein},
    Title = {{The Missing Links: Bugs and Bug-fix Commits}},
	Booktitle = {SIGSOFT '10/FSE-18: Proceedings of the 16th ACM SIGSOFT Symposium  on Foundations of Software Engineering},
	Publisher = {ACM},
	Year = {2010},
	acceptance = {20\%},
	abbrv = {FSE 10},
	pdf = {bachman2010mlb.pdf},
    Abstract = {
    Empirical studies of software defects rely on links between bug databases and
    program code repositories.  This linkage is typically based on bug-fixes
    identified in manually-entered commit logs.  Unfortunately, developers do not
    always report which commits perform bug-fixes.  Prior work suggests that such
    links can be a biased sample of the entire population of fixed bugs.  The
    validity of statistical hypotheses-testing  based on linked data could well be
    affected by bias.  Given the  wide use of  linked defect data, it is vital to
    gauge the nature and extent of the bias, and try to develop testable theories
    and models of the bias.  To do this, we must establish ground truth:
    manually analyze a complete version history corpus, and nail down those commits
    that fix defects, and those that are not.  This is a difficult task, requiring
    an expert to compare versions, analyze changes,  find related bugs in the bug
    database, reverse-engineer missing links, and finally record their work for use
    later. This  effort must be repeated for hundreds of commits to obtain a useful
    sample of reported and unreported bug-fix commits.  We make several
    contributions.  First, we present Linkageur, a tool to facilitate link
    reverse-engineering.  Second, we evaluate this tool, engaging a core developer
    of the Apache Webserver project to exhaustively annotate over all five hundred
    commits that occurred during a six week period.  Finally, we analyze this
    comprehensive data set, showing that there are serious and consequential
    problems in the data. 
    }
}

@inproceedings{posnett2010tmm,
    Author = {Daryl Posnett and Christian Bird and Premkumar Devanbu},
    Title = {{Thex: Mining Metapatterns in Java}},
	Booktitle = {Proceedings of the Seventh Working Conference on Mining Software Repositories},
	publisher = {IEEE Computer Society},
	location = {Cape Town, South Africa},
	acceptance = {31\%},
    Year = {2010},
	abbrv = {MSR 10},
	date = {3-23-2010},
	pdf = {posnett2010tmm.pdf},
    abstract = {
        Design patterns are codified solutions to common object-oriented design
            (OOD) problems in software development.  One of the proclaimed
            benefits of the use of design patterns is that they decouple
            functionality and enable different parts of a system to change
            frequently without undue disruption throughout the system.  These
            OOD  patterns have received a wealth of attention in the research
            community since their introduction; however, identifying them in
            source code is a difficult problem.  In contrast, metapatterns have
            similar effects on software design, by enabling portions of the
            system to be extended or modified easily, but are purely structural
            in nature, and thus easier to detect.  Our long-term goal is to
            evaluate the effects of  different OOD patterns on coordination in
            software teams as well as outcomes such as developer productivity
            and software quality.  In this paper we present Thex, a metapattern
            detector which scales to large codebases and works on any Java
            bytecode.  We evaluate Thex by examining its performance on
            codebases with known design patterns (and therefore metapatterns)
            and find that it performs quite well, with recall of over 90\%.

    }

        
}

@inproceedings{rahman2010cws-esem,
    Author = {Foyzur Rahman and Christian Bird and Premkumar Devanbu},
    Title = {{Clones: What \emph{is} that Smell?}},
    html_title = {{Clones: What <em>is</em> that Smell?}},
	Booktitle = {Proceedings of the fourth International Symposium on Empirical Software Engineering and Measurement},
	publisher = {IEEE Computer Society},
	location = {Bolzano, Italy},
	acceptance = {invited paper},
    Year = {2010},
    date = {9-16-2010},
    abbrv = {ESEM 10},
	pdf = {rahman2010cws.pdf},
    html_abstract = {
        Clones are generally considered bad programming practice in software
        engineering folklore. They are identified as a bad smell and a
        major contributor to project maintenance difficulties. Clones
        inherently cause code bloat, thus increasing project size and
        maintenance costs. In this work, we try to validate the
        conventional wisdom empirically to see whether cloning makes code
        more defect prone.
<br>
        This paper analyses relationship between cloning and defect proneness.
        We find that, first,  the great majority of bugs are not significantly
        associated with clones. Second, we find that clones may be less defect
        prone than non-cloned code.  Finally,  we find little evidence that
        clones with more copies are actually more error prone.  Our findings
        don't support the claim that clones are really a "bad smell".  Perhaps
        we can clone, <em>and</em> breathe easy, at the same time.  
    }
}


@inproceedings{rahman2010cws,
    Author = {Foyzur Rahman and Christian Bird and Premkumar Devanbu},
    Title = {{Clones: What \emph{is} that Smell?}},
    html_title = {{Clones: What is that Smell?}},
	Booktitle = {Proceedings of the Seventh Working Conference on Mining Software Repositories},
	publisher = {IEEE Computer Society},
	location = {Cape Town, South Africa},
	acceptance = {31\% Best Paper Award 1\%},
    Year = {2010},
    date = {3-16-2010},
    abbrv = {MSR 10},
	pdf = {rahman2010cws.pdf},
	award = {MSR Best Paper Award},
    abstract = {
        Clones are generally considered bad programming practice in software
        engineering folklore. They are identified as a bad smell and a
        major contributor to project maintenance difficulties. Clones
        inherently cause code bloat, thus increasing project size and
        maintenance costs. In this work, we try to validate the
        conventional wisdom empirically to see whether cloning makes code
        more defect prone.
	<br>
        This paper analyses relationship between cloning and defect proneness.
        We find that, first,  the great majority of bugs are not significantly
        associated with clones. Second, we find that clones may be less defect
        prone than non-cloned code.  Finally,  we find little evidence that
        clones with more copies are actually more error prone.  Our findings
        don't support the claim that clones are really a "bad smell".  Perhaps
        we can clone, and breathe easy, at the same time.  
    }
}

@inproceedings{nia2010vna,
    Author = {Roozbeh Nia and Christian Bird and Premkumar Devanbu and Vladimir Filkov},
    title = {Validity of Network Analyses in Open Source Projects},
	Booktitle = {Proceedings of the Seventh Working Conference on Mining Software Repositories},
	publisher = {IEEE Computer Society},
	acceptance = {31\%},
	location = {Cape Town, South Africa},
    pdf = {nia2010vna.pdf},
    year={2010},
    date = {3-16-2010},
    abbrv = {MSR 10},
    abstract = {

    Social  network  methods are frequently used to analyze networks derived
        from Open Source Project communication and collaboration data. Such
        studies typically discover patterns in the information flow between
        contributors or contributions in these projects. Social network metrics
        have also been used to predict defect occurrence.  However, such
        studies often ignore or side-step the issue of whether (and in what
        way) the metrics and networks of study are influenced by
        inadequate or missing data.
<br>
    In previous studies email archives of OSS projects have provided a useful
    trace of the communication and co-ordination activities of the
    participants.  These traces have been used to construct social networks
    that are then subject to various types of analysis.  However, during the
    construction of these networks, some assumptions are made, that may not
    always hold; this leads to incomplete, and sometimes incorrect networks.
    THe question then becomes, do these errors affect the validity of the
    ensuing analysis?  In this paper we specifically examine the stability of
    network metrics in the presence of inadequate and missing data. The issues
    that we study are: 1) the effect of paths with broken information flow
    (i.e. consecutive edges which are out of temporal order) on measures of
    centrality of nodes in the network, and 2) the effect of missing links on
    such measures. We demonstrate on three different OSS projects that while
    these issues do change network topology, the metrics used in the analysis
    are stable with respect to such changes. 

    }
}

@article{posnett2010esi,
    Author = {Daryl Posnett and Christian Bird and Premkumar Devanbu},
    Title = {{An Empirical Study on the Influence of Pattern Roles on Change-Proneness}},
    Journal = {Empirical Software Engineering, An International Journal},
	Publisher = {Springer-Verlag},
    issn = {1382-3256},
    Year = {2010},
    abbrv = {ESE},
    date = {1-23-2011},
    pages = {1-28},
    url = {http://dx.doi.org/10.1007/s10664-010-9148-2},
	abstract = {
		
	Identifying change-prone sections of code can help managers plan and allocate
	maintenance effort. Design patterns have been used to study
	change-proneness and are widely believed to support certain kinds of
	changes, while inhibiting others. Recently, several studies have analyzed
	recorded changes to classes playing design pattern roles and find that the
	patterns "folklore" offers a reasonable explanation for the reality:
	certain pattern roles do seem to be less change-prone than others. We push
	this analysis on two fronts: first, we deploy W. Pree's metapatterns, which
	group patterns purely by structure (rather than intent), and argue that
	metapatterns are a simpler model to explain recent findings by Di Penta et
	al. (2008). Second, we study the effect of the size of the classes playing
	the design pattern and metapattern roles. We find that size explains more
	of the variance in change-proneness than either design pattern or
	metapattern roles. We also find that both design pattern and metapattern
	roles were strong determinants of size. We conclude, therefore, that size
	appears to be a stronger determinant of change-proneness than either design
	pattern or metapattern roles, and observed differences in change-proneness
	between roles might be due to differences in the sizes of the classes
	playing those roles. The size of a class can be found much more quickly,
	easily and accurately than its pattern-roles. Thus, while identifying design
	pattern roles may be important for other reasons, as far as identifying
	change-prone classes, sheer size might be a better indicator.

	}

}

@inproceedings{bird2009pat,
	Author = {Christian Bird and Nachiappan Nagappan and Premkumar Devanbu and Harald Gall and Brendan Murphy},
	Booktitle = {Proceedings of the 17th International Symposium on Software Reliability Engineering},
	Title = {{Putting it All Together: Using Socio-Technical Networks to Predict Failures} },
	publisher = {IEEE Computer Society},
	Year = {2009},
	acceptance = {25\%},
	location = {Bengaluru-Mysuru, India},
	abbrv={ISSRE 09},
	date = {10-3-2009},
	pdf = {bird2009pat.pdf},
	abstract = {Studies have shown that social factors in development organizations have a
dramatic effect on software quality.  Separately,  program dependency
information has also been used successfully to predict which software components
are more fault prone. Interestingly, the influence of these two phenomena  have
only been studied separately.  Intuition and practical experience suggests,
however, that task assignment (i.e. who worked on which components and how
much) and dependency structure (which components have dependencies on others)
together interact to  influence the quality of the resulting software.  We
study the influence of  combined socio-technical software networks on
the fault-proneness of individual software components within a system.  The
network  properties of a software component in this  combined network are able
to predict if an entity is failure prone with greater accuracy than prior
methods which use dependency or contribution information in isolation.  We
evaluate our approach in different settings by using it on Windows Vista and
across six releases of the Eclipse development environment including using
models built from one release to predict failure prone components in the next
release.  We compare this to previous work.  In every case, our method performs
as well or better and is able to more accurately identify those software
components that have more post-release failures, with precision and recall
rates as high as 85\%.}
}

@inproceedings{bird2009fbb,
	Author = {Christian Bird and Adrian Bachmann and Eirik Aune and John Duffy and Abraham Bernstein and
	Vladimir Filkov and Premkumar Devanbu},
	Booktitle = {Proceedings of the the Seventh joint meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering},
	Location = {Amsterdam, Netherlands},
	Title = {{Fair and Balanced? Bias in Bug-Fix Datasets} },
	Year = {2009},
	acceptance = {14\%},
	date = {7-12-2009},
	publisher = {ACM},
	abbrv = {FSE 09},
	pdf = {bird2009fbb.pdf},
	abstract = {Software engineering researchers have long been interested in
where and why bugs occur in code, and in predicting where they might
turn up next. Historical bug-occurence data has been key to this
research.  Bug tracking systems, and code version histories, record
when, how and by whom bugs were fixed; from these sources,  datasets
that  relate file changes to bug fixes can be extracted. These
historical datasets   can be used to test hypotheses concerning
processes of bug introduction, and also to build statistical bug
prediction models.  Unfortunately, processes and humans are imperfect,
and only a fraction of bug fixes are actually labelled in source
code version histories, and thus become available for study in the
extracted datasets. The question naturally arises, are the bug fixes
recorded in these historical datasets a fair representation of the full
population of bug fixes?  In this paper, we investigate historical data
from several software projects, and find strong evidence of systematic
bias. We then investigate the potential effects of "unfair,
imbalanced" datasets on the performance of prediction techniques.  We
draw the lesson that bias is a critical problem that threatens  both
the effectiveness of processes that rely on biased datasets to build
prediction models and the generalizability of hypotheses tested on
biased data}
}

@inproceedings{bird2009ppm,
	Address = {Washington, DC, USA},
	Author = {Christian Bird and Peter C. Rigby and Earl T. Barr and David J. Hamilton and Daniel M. German and Prem Devanbu},
	Booktitle = {Proceedings of the Sixth Working Conference on Mining Software Repositories},
	Publisher = {IEEE Computer Society},
	Title = {{The Promises and Perils of Mining Git}},
	Year = {2009},
	acceptance = {28\%},
	location = {Vancouver, Canada},
	abbrv = {MSR 09},
	date = {3-28-2009},
	pdf = {bird2009ppm.pdf},
	abstract = {We are now witnessing the rapid growth of  decentralized source code
management (DSCM) systems, in which every developer has her own repository. 
DSCMs facilitate a style of collaboration in which
 work output can flow sideways (and privately)
 between collaborators, rather than always
up and down (and publicly) via a central repository. 
Decentralization comes with both the promise of new data and the peril of its
misinterpretation. 
We focus on git, a very popular DSCM used in high-profile projects. 
Decentralization, and other features of git, such as automatically recorded
contributor attribution, lead to richer content histories, 
giving rise to new questions such as ``How do contributions flow
between developers to the official project repository?''
However, there are pitfalls. 
Commits may be reordered, deleted, or edited as they move between repositories.
The semantics of terms common to SCMs and DSCMs sometimes differ markedly,
potentially creating confusion.  
For example, a commit is immediately visible
to all developers in centralized SCMs, but not in DSCMs. 
Our goal is to help researchers interested in DSCMs avoid  these and other
perils when mining and analyzing git data.}

}

@inproceedings{bird2009sdr,
	Author = {Christian Bird and Earl Barr and   Andre Nash and Premkumar Devanbu and Vladimir Filkov   and Zhendong Su},
	Booktitle = {Proceedings of the Ninth SIAM International Conference on Data Mining},
	Location = {Sparks, Nevada, USA},
	Publisher = {SIAM},
	Title = {{Structure and Dynamics of Research Collaboration in Computer Science} },
	Year = {2009},
	pages = {826--837},
	acceptance = {29\%},
	acceptance_long = {29\%\footnote{SDM paper accepted in full as a poster presentation paper.  15\% of papers accepted for presentation and 14\% were accepted as for poster presentation.}},
	abbrv = {SDM 09},
	pdf = {bird2009sdr.pdf},
	short_venue = {SDM 09},
	date = {11-4-2009},
	abstract = {Complex systems exhibit emergent patterns of behavior at different levels of
organization. Powerful network analysis methods, developed in physics and
social sciences, have been successfully used to tease out patterns that
relate to community structure and network dynamics.  In this paper, we mine
the complex network of collaboration relationships in computer science, and
adapt these network analysis methods to study collaboration and
interdisciplinary research at the individual, within-area and network-wide
levels.  
<br>
We start with a collaboration graph extracted from the DBLP bibliographic
database and use extrinsic data to define research areas within computer
science.  Using topological measures on the collaboration graph, we find
significant differences in the behavior of individuals among areas based on
their collaboration patterns. We use community structure analysis,
betweenness centralization, and longitudinal assortativity as metrics within
each area to determine how centralized, integrated, and cohesive they are.
Of special interest is how research areas change with time. We
longitudinally examine the area overlap and migration patterns of authors,
and empirically confirm some computer science folklore.
<br>
We also examine the degree to which the research areas and their key
conferences are interdisciplinary.  We find that data mining and software
engineering are very interdisciplinary while theory and cryptography are
not.  Specifically, it appears that SDM and ICSE attract authors who publish
in many areas while FOCS and STOC do not.  We also examine isolation both
within and between areas.  One interesting discovery is that cryptography is
highly isolated within the larger computer science community, but densely
interconnected within itself.}
}

@article{bird2009dddb,
	Author = {Christian Bird and Nachiappan Nagappan and   Premkumar Devanbu and Harald Gall and Brendan Murphy},
	journal = {Communications of the ACM},
	Title = {{Does Distributed Development Affect Software Quality? An Empirical Case Study of Windows Vista} },
	publisher = {ACM},
	address = {New York, NY, USA},
	Month = {August},
	volume = {52},
	number = {8},
	pages = {85--93},
	pdf = {http://portal.acm.org/citation.cfm?id=1536639},
	short_venue = {CACM},
	Year = {2009},
	date = {8-10-2009},
	acceptance = {Revised edition of ICSE paper invited to Research Highlights in CACM},
	abstract = {Existing literature on distributed 
development in software engineering, and other fields discuss various challenges, 
including cultural barriers, expertise transfer difficulties, and communication 
and coordination overhead.  Conventional wisdom, in  fact, holds 
that distributed software development is riskier and 
more challenging than collocated development. 
We revisit this belief, empirically studying
the overall development of Windows Vista and comparing the post-release failures 
of components that were developed in a distributed fashion with those that were 
developed by collocated teams.  We found a negligible difference in failures.  
This difference becomes even less significant when controlling for the number
of developers working on a binary.  Furthermore, we also found that component characteristics
(such as code churn, complexity, dependency information, and test code coverage)
differ very little between distributed and collocated components.
Finally, we  examine the software process used during the Vista
development cycle and  examine how it may have
mitigated some of the difficulties of distributed development
introduced in
prior work in this area.}
}

@inproceedings{bird2009ddd,
	Author = {Christian Bird and Nachiappan Nagappan and   Premkumar Devanbu and Harald Gall and Brendan Murphy},
	Booktitle = {Proceedings of the 31st International Conference on Software Engineering},
	Location = {Vancouver, Canada},
	Title = {{Does Distributed Development Affect Software Quality? An Empirical   Case Study of Windows Vista} },
	Year = {2009},
	publisher = {IEEE Computer Society},
	pages = {518--528},
	acceptance = {12\% Best Paper Award 1\%},
	award = {ACM Distinguished Paper Award},
	abbrv = {ICSE 09},
	pdf = {bird2009ddd.pdf},
	date = {2-12-2009},
	abstract = {Existing literature on distributed 
development in software engineering, and other fields discuss various challenges, 
including cultural barriers, expertise transfer difficulties, and communication 
and coordination overhead.  Conventional wisdom, in  fact, holds 
that distributed software development is riskier and 
more challenging than collocated development. 
We revisit this belief, empirically studying
the overall development of Windows Vista and comparing the post-release failures 
of components that were developed in a distributed fashion with those that were 
developed by collocated teams.  We found a negligible difference in failures.  
This difference becomes even less significant when controlling for the number
of developers working on a binary.  Furthermore, we also found that component characteristics
(such as code churn, complexity, dependency information, and test code coverage)
differ very little between distributed and collocated components.
Finally, we  examine the software process used during the Vista
development cycle and  examine how it may have
mitigated some of the difficulties of distributed development
introduced in
prior work in this area.}
}

@inproceedings{bird2008lss,
	Address = {New York, NY, USA},
	Author = {Christian Bird and David Pattison and Raissa D'Souza and   Vladimir Filkov and Premkumar Devanbu},
	Booktitle = {SIGSOFT '08/FSE-16: Proceedings of the 16th ACM SIGSOFT Symposium  on Foundations of Software Engineering},
	Location = {Atlanta, Georgia, USA},
	Pages = {24--35},
	Publisher = {ACM},
	Title = {{Latent Social Structure in Open Source Projects} },
	Year = {2008},
	acceptance = {20\%},
	abbrv = {FSE 08},
	pdf = {bird2008lss.pdf},
	date = {7-12-2008},
	short_venue = {FSE 08},
	abstract = {Commercial software project managers design
project organizational structure carefully, mindful of available skills,
division of labour, geographical boundaries, etc.  These organizational
	"cathedrals" are to be contrasted with the "bazaar-like" nature of
	Open Source Software (OSS) Projects, which  have no pre-designed
	organizational structure.  Any structure that exists is dynamic,
self-organizing, latent, and usually not explicitly stated.  Still, in  large,
complex, successful, OSS projects, we do expect that subcommunities will form
	spontaneously within the developer  teams.  Studying these
	subcommunities,  and  their behavior can shed light on how successful
	OSS projects  self-organize.  This phenomenon could well hold important
	lessons for how commercial software teams might be organized.  Building
	on known well-established techniques for detecting community structure
	in complex networks, we extract and study latent subcommunities from
	the email social network of several projects: Apache HTTPD, Python,
PostgresSQL, Perl, and Apache ANT.  We then validate them with software
	development activity history.  Our results show that subcommunities do
	indeed spontaneously arise within these projects as the projects
	evolve.  These subcommunities  manifest most strongly in technical
	discussions, and are significantly connected with collaboration
	behaviour.}

}

@inproceedings{pattison2008twp,
	Address = {New York, NY, USA},
	Author = {David Pattison and Christian Bird and Premkumar Devanbu},
	Booktitle = {Proceedings of the Fifth International Working Conference on Mining Software Repositories},
	Doi = {http://doi.acm.org/10.1145/1370750.1370776},
	Isbn = {978-1-60558-024-1},
	Location = {Leipzig, Germany},
	Pages = {113--116},
	Publisher = {ACM},
	Title = {{Talk and Work: a Preliminary Report} },
	Year = {2008},
	acceptance = {40\%},
	abbrv = {MSR 08},
	pdf = {pattison2008twp.pdf},
	date = {4-3-2008},
	short_venue = {MSR 08},
	abstract = {
		Developers in Open Source Software (OSS) projects communicate
using mailing lists. By convention, the mailing lists
are used only for task-related discussions, so they are primarily
concerned with the software under development, and
software process issues (releases, etc.). We focus on the discussions
concerning the software, and study the frequency
with which software entities (functions, methods, classes,
etc) are mentioned in the mail. We find a strong, striking,
cumulative relationship between this mention count in the
email, and the number of times these entities are included
in changes to the software. When we study the same phenomena
over a series of time-intervals, the relationship is
much less strong. This suggests some interesting avenues
for future research.
	}
}

@inproceedings{saul2007rrw,
	Address = {New York, NY, USA},
	Author = {Zachary M. Saul and Vladimir Filkov and Premkumar Devanbu and Christian Bird},
	Booktitle = {ESEC-FSE '07: Proceedings of the the Sixth joint meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering},
	Doi = {http://doi.acm.org/10.1145/1287624.1287629},
	Isbn = {978-1-59593-811-4},
	Location = {Dubrovnik, Croatia},
	Pages = {15--24},
	Publisher = {ACM},
	Title = {{Recommending Random Walks} },
	Year = {2007},
	acceptance = {17\%, nominated for Best Paper},
	abbrv = {FSE 07},
	short_venue = {FSE 07},
	date = {7-3-2007},
	pdf = {fse-2007.pdf},
	abstract = {
We improve on previous recommender systems by taking
advantage of the layered structure of software. We use a
random-walk approach, mimicking the more focused behavior
of a developer, who browses the caller-callee links in the
callgraph of a large program, seeking routines that are likely
to be related to a function of interest. Inspired by Kleinbergs
work, we approximate the steady-state of an infinite random walk on a subset of a callgraph in order to rank
the functions by their steady-state probabilities. Surprisingly,
this purely structural approach works quite well. Our
approach, like that of Robillards "Suade" algorithm, and
earlier data mining approaches relies solely on the always
available current state of the code, rather than other
sources such as comments, documentation or revision information.
Using the Apache API documentation as an oracle,
we perform a quantitative evaluation of our method, finding
that our algorithm dramatically improves upon Suade
in this setting. We also find that the performance of traditional
data mining approaches is complementary to ours;
this leads naturally to an evidence-based combination of the
two, which shows excellent performance on this task.
	}
		
}

@inproceedings{bird2007dps,
	Address = {Washington, DC, USA},
	Author = {Christian Bird and Alex Gourley and Prem Devanbu},
	Booktitle = {Proceedings of the Fourth International Workshop on Mining Software Repositories},
	Doi = {http://dx.doi.org/10.1109/MSR.2007.6},
	Isbn = {0-7695-2950-X},
	Pages = {26--35},
	Publisher = {IEEE Computer Society},
	Title = {{Detecting Patch Submission and Acceptance in OSS Projects} },
	Year = {2007},
	acceptance = {38\%},
	location = {Minneapolis, Minnesota, USA},
	abbrv = {MSR 07},
	pdf = {bird2007dps},
	short_venue = {MSR 07},
	date = {5-10-2007},
	tags = {mining, email, social networks},
	abstract = {
		The success of open source software (OSS) is completely
dependent on the work of volunteers who contribute
their time and talents. The submission of
patches is the major way that participants outside of
the core group of developers make contributions. We
argue that the process of patch submission and acceptance
into the codebase is an important piece of the
open source puzzle and that the use of patch-related
data can be helpful in understanding how OSS projects
work. We present our methods in identifying the submission
and acceptance of patches and give results and
evaluation in applying these methods to the Apache
webserver, Python interpreter, Postgres SQL database,
and (with limitations) MySQL database projects. In
addition, we present valuable ways in which this data
has been and can be used.
	}
}

@inproceedings{ogawa2007vsi,
	Author = {Michael Ogawa and Kwan-Liu Ma and Christian Bird and Premkumar T. Devanbu and                Alex Gourley},
	Booktitle = {Sixth International Asia-Pacific Symposium on Visualization},
	Pages = {25--32},
	Title = {{Visualizing Social Interaction in Open Source Software Projects} },
	Year = {2007},
	acceptance = {45\%},
	abbrv = {APVIS 07},
	short_venue = {APVIS 07},
	date = {2-5-2007},
	pdf = {apvisogawa.pdf},
	abstract = {
		Open source software projects such as Apache and Mozilla present
an opportunity for information visualization. Since these projects
typically require collaboration between developers located far
apart, the amount of electronic communication between them is
large. Our goal is to apply information visualization techniques
to assist software engineering scientists and project managers with
analyzing the data.
<br>
We present a visualization technique that provides an intuitive,
time-series, interactive summary view of the the social groups that
form, evolve and vanish during the entire lifetime of the project.
This visualization helps software engineering researchers understand
the organization, structure, and evolution of the communication
and collaboration activities of a large, complex software
project.
	}
}

@inproceedings{bird2007obi,
	Address = {Washington, DC, USA},
	Author = {Christian Bird and Alex Gourley and Prem Devanbu and Anand Swaminathan and Greta Hsu},
	Booktitle = {Proceedings of the Fourth International Workshop on Mining Software Repositories},
	Doi = {http://dx.doi.org/10.1109/MSR.2007.23},
	Isbn = {0-7695-2950-X},
	Pages = {6},
	Publisher = {IEEE Computer Society},
	Title = {{Open Borders? Immigration in Open Source Projects} },
	Year = {2007},
	acceptance = {38\%},
	location = {Minneapolis, Minnesota, USA},
	abbrv = {MSR 07},
	pdf = {bird2007obi.pdf},
	short_venue = {MSR 07},
	date = {5-10-2007},
	tags = {mining, email, social networks},
	abstract = {Open source software is built by teams of volunteers.
Each project has a core team of developers, who have
the authority to commit changes to the repository; this
team is the elite, committed foundation of the project,
selected through a meritocratic process from a larger
number of people who participate on the mailing list.
Most projects carefully regulate admission of outsiders
to full developer privileges; some projects even have
formal descriptions of this process. Understanding the
factors that influence the "who, how and when" of this
process is critical, both for the sustainability of FLOSS
projects, and for outside stakeholders who want to gain
entry and succeed. In this paper we mount a quantitative
case study of the process by which people join
FLOSS projects, using data mined from the Apache web
server, Postgres, and Python. We develop a theory of
open source project joining, and evaluate this theory
based on our data.}
}

@inproceedings{bird2006mes,
	Address = {New York, NY, USA},
	Author = {Christian Bird and Alex Gourley and Prem Devanbu and Michael Gertz and Anand Swaminathan},
	Booktitle = {Proceedings of the Third International Workshop on Mining software repositories},
	Doi = {http://doi.acm.org/10.1145/1137983.1138016},
	Isbn = {1-59593-397-2},
	Location = {Shanghai, China},
	Pages = {137--143},
	Publisher = {ACM},
	Title = {{Mining Email Social Networks} },
	Year = {2006},
	acceptance = {35\%},
	date = {4-10-2006},
	short_venue = {MSR 06},
	abbrv = {MSR 06},
	tags = {mining, social networks, email},
	pdf = {msr06.pdf},
	abstract = {
		Communication and Coordination activities are central to
large software projects, but are difficult to observe and study
in traditional (closed-source, commercial) settings because
of the prevalence of informal, direct communication modes.
OSS projects, on the other hand, use the internet as the
communication medium, and typically conduct discussions
in an open, public manner. As a result, the email archives
of OSS projects provide a useful trace of the communication
and co-ordination activities of the participants. However,
there are various challenges that must be addressed
before this data can be effectively mined. Once this is done,
we can construct social networks of email correspondents,
and begin to address some interesting questions. These include
questions relating to participation in the email; the
social status of different types of OSS participants; the relationship
of email activity and commit activity (in the CVS
repositories) and the relationship of social status with commit
activity. In this paper, we begin with a discussion of
our infrastructure and then discuss our approach to mining
the email archives; and finally we present some preliminary
results from our data analysis.
	}
}

@inproceedings{bird2006mesp,
	Address = {New York, NY, USA},
	Author = {Christian Bird and Alex Gourley and Prem Devanbu and Michael Gertz and Anand Swaminathan},
	Booktitle = {Proceedings of the Third International Workshop on Mining software repositories (Challenge Track)},
	Doi = {http://doi.acm.org/10.1145/1137983.1138033},
	Isbn = {1-59593-397-2},
	Location = {Shanghai, China},
	Pages = {185--186},
	Publisher = {ACM},
	Title = {{Mining Email Social Networks in Postgres} },
	Year = {2006},
	date = {4-10-2006},
	short_venue = {MSR 06},
	abbrv = {MSR '06},
	pdf = {msrchallenge2006.pdf},
	tags = {mining, social networks, email},
	abstract = {Open Source Software (OSS) projects provide a unique opportunity
to gather and analyze publicly available historical data. The Postgres
SQL server, for example, has over seven years of recorded development
and communication activity. We mined data from both
the source code repository and the mailing list archives to examine
the relationship between communication and development in Postgres.
Along the way, we had to deal with the difficult challenge of
resolving email aliases. We used a number of social network analysis
measures and statistical techniques to analyze this data. We
present our findings in this paper.}
}
